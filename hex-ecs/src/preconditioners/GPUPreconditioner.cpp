//  * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *  //
//                                                                                   //
//                       / /   / /    __    \ \  / /                                 //
//                      / /__ / /   / _ \    \ \/ /                                  //
//                     /  ___  /   | |/_/    / /\ \                                  //
//                    / /   / /    \_\      / /  \ \                                 //
//                                                                                   //
//                                                                                   //
//  Copyright (c) 2016, Jakub Benda, Charles University in Prague                    //
//                                                                                   //
// MIT License:                                                                      //
//                                                                                   //
//  Permission is hereby granted, free of charge, to any person obtaining a          //
// copy of this software and associated documentation files (the "Software"),        //
// to deal in the Software without restriction, including without limitation         //
// the rights to use, copy, modify, merge, publish, distribute, sublicense,          //
// and/or sell copies of the Software, and to permit persons to whom the             //
// Software is furnished to do so, subject to the following conditions:              //
//                                                                                   //
//  The above copyright notice and this permission notice shall be included          //
// in all copies or substantial portions of the Software.                            //
//                                                                                   //
//  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS          //
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,       //
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE       //
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, //
// WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF         //
// OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.  //
//                                                                                   //
//  * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *  //

#if (defined(WITH_OPENCL) && !defined(NO_LAPACK))

#include <iostream>
#include <set>

#include "hex-arrays.h"
#include "hex-itersolve.h"
#include "hex-misc.h"
#include "hex-special.h"

#include "clarrays.h"
#include "gauss.h"
#include "preconditioners.h"
#include "radial.h"

#include <CL/cl.h>

const std::string GPUCGPreconditioner::prec_name = "GPU";
const std::string GPUCGPreconditioner::prec_description = "Block inversion using conjugate gradients preconditioned by Kronecker product approximation (on GPU).";

// kernels' source as byte array, generated by "xxd" from the CL source
#include "GPUPreconditioner.inc"

void GPUCGPreconditioner::setup ()
{
    KPACGPreconditioner::setup();
    
    // check zero panel
    if (bspline_atom_.hash() != bspline_proj_.hash())
        HexException("GPU preconditioner only supports #0 panel (use KPA for further panels).");
    
    // create program source, append zero
    std::string source;
    source.resize(src_preconditioners_GPUPreconditioner_cl_len + 1);
    for (unsigned i = 0; i < src_preconditioners_GPUPreconditioner_cl_len; i++)
        source[i] = src_preconditioners_GPUPreconditioner_cl[i];
    source.back() = '\0';
    
    // shorthands
    int order = bspline_atom_.order();
    int Nspline_atom = bspline_atom_.Nspline();
    int Nreknot_atom = bspline_atom_.Nreknot();
    int Nspline_proj = bspline_proj_.Nspline();
    int Nreknot_proj = bspline_proj_.Nreknot();
    
    // auxiliary variables
    char platform_name[1024], platform_vendor[1024], platform_version[1024], device_name[1024], device_vendor[1024];
    cl_platform_id platforms[10]; cl_uint nplatforms;
    cl_device_id devices[10]; cl_uint ndevices;
    
    {
        std::cout << "Available OpenCL devices" << std::endl;
        clGetPlatformIDs(10, platforms, &nplatforms);
        for (cl_uint i = 0; i < nplatforms; i++)
        {
            clGetPlatformInfo(platforms[i], CL_PLATFORM_NAME, sizeof(platform_name), platform_name, nullptr);
            clGetPlatformInfo(platforms[i], CL_PLATFORM_VENDOR, sizeof(platform_vendor), platform_vendor, nullptr);
            clGetPlatformInfo(platforms[i], CL_PLATFORM_VERSION, sizeof(platform_version), platform_version, nullptr);
#ifdef __linux__
                if (i == cmd_.ocl_platform and isatty(STDOUT_FILENO))
                    std::cout << "\x1B[1;37m";
#endif
            std::cout << "\t- Platform " << i << ": " << platform_name << " (" << platform_vendor << ", " << platform_version << ")" << std::endl;
#ifdef __linux__
                if (i == cmd_.ocl_platform and isatty(STDOUT_FILENO))
                    std::cout << "\x1B[0m";
#endif
            clGetDeviceIDs(platforms[i], CL_DEVICE_TYPE_ALL, 10, devices, &ndevices);
            for (cl_uint j = 0; j < ndevices; j++)
            {
                clGetDeviceInfo(devices[j], CL_DEVICE_NAME, sizeof(device_name), device_name, nullptr);
                clGetDeviceInfo(devices[j], CL_DEVICE_VENDOR, sizeof(device_vendor), device_vendor, nullptr);
#ifdef __linux__
                if (i == cmd_.ocl_platform and j == cmd_.ocl_device and isatty(STDOUT_FILENO))
                    std::cout << "\x1B[1;37m";
#endif
                std::cout << "\t\t- Device " << j << ": " << device_name << " (" << device_vendor << ")" << std::endl;
#ifdef __linux__
                if (i == cmd_.ocl_platform and j == cmd_.ocl_device and isatty(STDOUT_FILENO))
                    std::cout << "\x1B[0m";
#endif
            }
        }
        std::cout << std::endl;
    }
    
    std::cout << "Setting up OpenCL environment" << std::endl;
    
    // check that the chosen platform is available
    clGetPlatformIDs(10, platforms, &nplatforms);
    if (cmd_.ocl_platform >= nplatforms)
        HexException("The requested platform index (%d) does not exist on this system. Run hex-ecs --cl-list to find all existing.", cmd_.ocl_platform);
    
    platform_ = platforms[cmd_.ocl_platform];
    clGetPlatformInfo(platform_, CL_PLATFORM_NAME, sizeof(platform_name), platform_name, nullptr);
    clGetPlatformInfo(platform_, CL_PLATFORM_VENDOR, sizeof(platform_vendor), platform_vendor, nullptr);
    clGetPlatformInfo(platform_, CL_PLATFORM_VERSION, sizeof(platform_version), platform_version, nullptr);
    
    std::cout << "\t- platform "<< cmd_.ocl_platform << ": " << platform_name << " (" << platform_vendor << ")" << std::endl;
    std::cout << "\t- available version: " << platform_version << std::endl;
    
    // check that the chosen device is available
    clGetDeviceIDs(platform_, CL_DEVICE_TYPE_ALL, 10, devices, &ndevices);
    if (cmd_.ocl_device >= ndevices)
        HexException("The requested device index (%d) does not exist for platform %d (ndevices = %d). Run hex-ecs --cl-list to find all existing.",  cmd_.ocl_device, cmd_.ocl_platform, ndevices);
    
    device_ = devices[cmd_.ocl_device];
    clGetDeviceInfo(device_, CL_DEVICE_NAME, sizeof(device_name), device_name, nullptr);
    clGetDeviceInfo(device_, CL_DEVICE_VENDOR, sizeof(device_vendor), device_vendor, nullptr);
    
    std::cout << "\t- device " << cmd_.ocl_device << ": " << device_name << " (" << device_vendor << ")" << std::endl;
    
    cl_ulong max_compute_units, max_work_group_size, local_memory_size, global_memory_size;
    clGetDeviceInfo(device_, CL_DEVICE_MAX_COMPUTE_UNITS, sizeof(cl_ulong), &max_compute_units, 0);
    clGetDeviceInfo(device_, CL_DEVICE_MAX_WORK_GROUP_SIZE, sizeof(cl_ulong), &max_work_group_size, 0);
    clGetDeviceInfo(device_, CL_DEVICE_LOCAL_MEM_SIZE, sizeof(cl_ulong), &local_memory_size, 0);
    clGetDeviceInfo(device_, CL_DEVICE_GLOBAL_MEM_SIZE, sizeof(cl_ulong), &global_memory_size, 0);
    
    std::cout << "\t- max compute units: " << max_compute_units << std::endl;
    std::cout << "\t- max work group size: " << max_work_group_size << std::endl;
    
    // choose default workgroup size
    Nlocal_ = std::min<std::size_t>(64, max_work_group_size);
    
    // choose block size for "mul_ABt" kernel, aim at 4 concurrent threads
    blocksize_ = std::sqrt(local_memory_size / (4/*threads*/ * 16/*double*/ * 2/*arrays*/));
    blocksize_ = std::min<std::size_t>(blocksize_, std::sqrt(max_work_group_size));
    std::cout << "\t- matrix multiplication tile size: " << blocksize_ << std::endl;
    
    // get block counts for --cl-multiply
    if (cmd_.gpu_host_multiply)
    {
        // use all blocks at once if using the host memory
        nsrcseg_ = ang_.states().size();
        ndstseg_ = ang_.states().size();
    }
    else
    {
        // determine how many solution segments will fit into the device memory
        unsigned memseg = 0.8 * global_memory_size / (bspline_atom_.Nspline() * bspline_proj_.Nspline() * sizeof(Complex));
        if (memseg < 2 and cmd_.gpu_multiply)
            HexException("Insufficent OpenCL device memory for lightweight on-device multiplication.");
        
        // calculate how many block rows will fit into the memory and what space will remain
        unsigned rows_fit = memseg / (ang_.states().size() + 1); rows_fit = std::min<unsigned>(rows_fit, ang_.states().size());
        unsigned cols_rmn = memseg % (ang_.states().size() + 1);
        
        // calculate how many source/destination vector segments will be processed at once
        nsrcseg_ = (rows_fit > 0 ? ang_.states().size() : cols_rmn);
        ndstseg_ = (rows_fit > 0 ? rows_fit             : 1       );
    }
    
    if (cmd_.gpu_multiply)
        std::cout << "\t- multiply blocks " << ndstseg_ << " × " << nsrcseg_ << std::endl;
    
    // compute global memory requirements of the preconditioner
    std::size_t greq = 0;
    // - Nspline*Nspline for: four preconditioner matrices, 5 CG arrays (x,b,r,p,z) and one temporary array (tmA)
    if (not cmd_.gpu_large_data)
        greq += 10 * (std::size_t)Nspline_atom * (std::size_t)Nspline_proj;
    // - padded one-electron matrices (S, D, M1, M2)
    greq += 4 * (rad_.S_atom().size() + rad_.S_proj().size());
    // - preconditioner eigenvalues
    greq += Nspline_atom + Nspline_proj;
    // - full integral moments
    greq += (rad_.maxlambda() + 1) * (rad_.S_atom().size() + rad_.S_proj().size());
    // - partial integral moments
    greq += 2 * rad_.Mitr_L_atom(-1).size() + rad_.Mitr_L_proj(-1).size();
    // - diagonal contribution to two-electron integrals
    if (bspline_atom_.hash() == bspline_proj_.hash() and not cmd_.gpu_large_data)
        greq += (rad_.maxlambda() + 1) * bspline_atom_.Nspline() * special::pow_int(bspline_atom_.order() + 1, 3);
    // - solution vector
    if (cmd_.gpu_multiply and not cmd_.gpu_host_multiply)
        greq = std::max(greq, (std::size_t)nsrcseg_ * ndstseg_ * bspline_atom_.Nspline() * bspline_proj_.Nspline());
    // - all these were complex numbers
    greq *= 16;
    
    std::cout << "\t- global memory size: " << format("%.2f", global_memory_size/gsl_sf_pow_int(1024,3)) << " GiB ";
    std::cout << "(apx. " << format("%.2f", greq * 100. / global_memory_size) << " % will be used)" << std::endl;
    
    if (cmd_.gpu_large_data)
    {
        std::size_t host_mem = 16 * 10 * (std::size_t)Nspline_atom * (std::size_t)Nspline_proj;
        if (cmd_.gpu_host_multiply)
            host_mem += 16 * nsrcseg_ * ndstseg_ * (std::size_t)bspline_atom_.Nspline() * (std::size_t)bspline_proj_.Nspline();
        std::cout << "\t- data kept in host memory: " << format("%.2f", host_mem/gsl_sf_pow_int(1024,3)) << " GiB " << std::endl;
        std::cout << "\t- WARNING: --ocl-use-host-memory will slow down the solution due to the host-device data transfers." << std::endl;
    }
    
    // compute local memory requirements of the preconditioner
    std::size_t lreq = 0;
    // - either Complex per default Nlocal_
    lreq = Nlocal_;
    // - or the requirements of mul_ABt
    lreq = std::max<std::size_t>(lreq, 2/*array*/ * 16/*double*/ * blocksize_);
    // - all these were complex numbers
    lreq *= 16;
    
    std::cout << "\t- local memory size: " << local_memory_size/1024 << " kiB ";
    std::cout << "(apx. " << format("%.2f", lreq * 100. / local_memory_size) << " % will be used)" << std::endl << std::endl;
    
    // create context and command queue
    context_ = clCreateContext(nullptr, 1, &device_, nullptr, nullptr, nullptr);
#ifdef CL_VERSION_2_0
    queue_ = clCreateCommandQueueWithProperties(context_, device_, nullptr, nullptr);
#else
    queue_ = clCreateCommandQueue(context_, device_, 0, nullptr);
#endif
    
    // setup compile flags
    std::ostringstream flags;
    flags << " -cl-fast-relaxed-math ";
    flags << " -D ORDER="        << order        << " ";
    flags << " -D NSPLINE_ATOM=" << Nspline_atom << " ";
    flags << " -D NSPLINE_PROJ=" << Nspline_proj << " ";
    flags << " -D NREKNOT_ATOM=" << Nreknot_atom << " ";
    flags << " -D NREKNOT_PROJ=" << Nreknot_proj << " ";
    flags << " -D NLOCAL="       << Nlocal_      << " ";
    flags << " -D BLOCK_SIZE="   << blocksize_   << " ";
    flags << " -D ANGULAR_BASIS_SIZE=" << ang_.states().size() << " ";
    flags << " -D NSRCSEG="      << nsrcseg_     << " ";
    flags << " -D NDSTSEG="      << ndstseg_     << " ";
    
    // build program
    const char * source_ptr = source.data();
    program_ = clCreateProgramWithSource(context_, 1, &source_ptr, nullptr, nullptr);
    clBuildProgram(program_, 1, &device_, flags.str().c_str(), nullptr, nullptr);
    
    cl_build_status status;
    clGetProgramBuildInfo(program_, device_, CL_PROGRAM_BUILD_STATUS, sizeof(status), &status, nullptr);
    if (status != CL_SUCCESS)
    {
        std::cout << std::endl << "Source:" << std::endl << source << std::endl;
        std::cout << std::endl << "Command line:" << std::endl << flags.str() << std::endl << std::endl;
        
        char log [100000];
        clGetProgramBuildInfo(program_, device_, CL_PROGRAM_BUILD_LOG, sizeof(log), log, nullptr);
        std::cout << "clGetProgramBuildInfo: log" << std::endl << log << std::endl;
        
        HexException("Failed to initialize OpenCL.");
    }
    
    // determine where to place the data (device / host)
    largeDataFlags_ = smallDataFlags_ = CL_MEM_READ_WRITE | CL_MEM_COPY_HOST_PTR;
    if (cmd_.gpu_large_data)
        largeDataFlags_ = CL_MEM_READ_WRITE | CL_MEM_USE_HOST_PTR;
    
    // set program entry points
    mml1_       = clCreateKernel(program_, "mmul_1el",        nullptr);
    mml2_       = clCreateKernel(program_, "mmul_2el",        nullptr);
    mml2_dcpl_  = clCreateKernel(program_, "mmul_2el_decoupled", nullptr);
    mml2_cpld_  = clCreateKernel(program_, "mmul_2el_coupled", nullptr);
    mml2_dcpl_offset_= clCreateKernel(program_, "mmul_2el_decoupled_offset", nullptr);
    mml2_cpld_offset_= clCreateKernel(program_, "mmul_2el_coupled_offset", nullptr);
    axby_       = clCreateKernel(program_, "a_vec_b_vec",     nullptr);
    norm_       = clCreateKernel(program_, "norm",            nullptr);
    spro_       = clCreateKernel(program_, "scalar_product",  nullptr);
    mabt_       = clCreateKernel(program_, "mul_ABt",         nullptr);
    krdv_       = clCreateKernel(program_, "kron_div",        nullptr);
    
    // round 'Nsegsiz' to nearest larger multiple of Nlocal_
    std::size_t Nsegsiz = Nspline_atom * Nspline_proj;
    std::size_t Nglobal = Nlocal_ * ((Nsegsiz + Nlocal_ - 1) / Nlocal_);
    
    // some OpenCL auxiliary storage arrays (used by kernels for temporary data)
    tmp_.resize(Nglobal / Nlocal_);              tmp_.connect(context_, smallDataFlags_);
    nrm_.resize(Nglobal / Nlocal_);              nrm_.connect(context_, smallDataFlags_);
    tmA_.resize(Nspline_atom * Nspline_proj);    tmA_.connect(context_, largeDataFlags_);
    
    // connect B-spline knots
    t_atom_.reset(bspline_atom_.t().size(), bspline_atom_.t().data());  t_atom_.connect(context_, smallDataFlags_);
    t_proj_.reset(bspline_proj_.t().size(), bspline_proj_.t().data());  t_proj_.connect(context_, smallDataFlags_);
    
    // create OpenCL representation of the one-electron matrices + transfer data to GPU memory
    S_atom_p_.reset(rad_.S_atom().data().size(), rad_.S_atom().data().data());                   S_atom_p_.connect(context_, smallDataFlags_);
    D_atom_p_.reset(rad_.D_atom().data().size(), rad_.D_atom().data().data());                   D_atom_p_.connect(context_, smallDataFlags_);
    Mm1_tr_atom_p_.reset(rad_.Mm1_tr_atom().data().size(), rad_.Mm1_tr_atom().data().data());    Mm1_tr_atom_p_.connect(context_, smallDataFlags_);
    Mm2_atom_p_.reset(rad_.Mm2_atom().data().size(), rad_.Mm2_atom().data().data());             Mm2_atom_p_.connect(context_, smallDataFlags_);
    
    S_proj_p_.reset(rad_.S_proj().data().size(), rad_.S_proj().data().data());                   S_proj_p_.connect(context_, smallDataFlags_);
    D_proj_p_.reset(rad_.D_proj().data().size(), rad_.D_proj().data().data());                   D_proj_p_.connect(context_, smallDataFlags_);
    Mm1_tr_proj_p_.reset(rad_.Mm1_tr_proj().data().size(), rad_.Mm1_tr_proj().data().data());    Mm1_tr_proj_p_.connect(context_, smallDataFlags_);
    Mm2_proj_p_.reset(rad_.Mm2_proj().data().size(), rad_.Mm2_proj().data().data());             Mm2_proj_p_.connect(context_, smallDataFlags_);
    
    // create OpenCL representation of the one-electron partial integral moments + transfer data to GPU memory
    Mi_L_atom_.resize(rad_.maxlambda() + 1); Mi_mLm1_atom_.resize(rad_.maxlambda() + 1);
    M_L_atom_.resize(rad_.maxlambda() + 1); M_mLm1_atom_.resize(rad_.maxlambda() + 1);
    for (int lambda = 0; lambda <= rad_.maxlambda(); lambda++)
    {
        Mi_L_atom_[lambda].reset(rad_.Mitr_L_atom(lambda).size(), rad_.Mitr_L_atom(lambda).data());
        Mi_mLm1_atom_[lambda].reset(rad_.Mitr_mLm1_atom(lambda).size(), rad_.Mitr_mLm1_atom(lambda).data());
        M_L_atom_[lambda].reset(rad_.Mtr_L_atom(lambda).data().size(), const_cast<Complex*>(rad_.Mtr_L_atom(lambda).data().data()));
        M_mLm1_atom_[lambda].reset(rad_.Mtr_mLm1_atom(lambda).data().size(), const_cast<Complex*>(rad_.Mtr_mLm1_atom(lambda).data().data()));
        
        Mi_L_atom_[lambda].connect(context_, smallDataFlags_);
        Mi_mLm1_atom_[lambda].connect(context_, smallDataFlags_);
        M_L_atom_[lambda].connect(context_, smallDataFlags_);
        M_mLm1_atom_[lambda].connect(context_, smallDataFlags_);
    }
    Mi_L_proj_.resize(rad_.maxlambda() + 1); Mi_mLm1_proj_.resize(rad_.maxlambda() + 1);
    M_L_proj_.resize(rad_.maxlambda() + 1); M_mLm1_proj_.resize(rad_.maxlambda() + 1);
    for (int lambda = 0; lambda <= rad_.maxlambda(); lambda++)
    {
        Mi_L_proj_[lambda].reset(rad_.Mitr_L_proj(lambda).size(), rad_.Mitr_L_proj(lambda).data());
        Mi_mLm1_proj_[lambda].reset(rad_.Mitr_mLm1_proj(lambda).size(), rad_.Mitr_mLm1_proj(lambda).data());
        M_L_proj_[lambda].reset(rad_.Mtr_L_proj(lambda).data().size(), const_cast<Complex*>(rad_.Mtr_L_proj(lambda).data().data()));
        M_mLm1_proj_[lambda].reset(rad_.Mtr_mLm1_proj(lambda).data().size(), const_cast<Complex*>(rad_.Mtr_mLm1_proj(lambda).data().data()));
        
        Mi_L_proj_[lambda].connect(context_, smallDataFlags_);
        Mi_mLm1_proj_[lambda].connect(context_, smallDataFlags_);
        M_L_proj_[lambda].connect(context_, smallDataFlags_);
        M_mLm1_proj_[lambda].connect(context_, smallDataFlags_);
    }
    Rdia_.resize(rad_.maxlambda() + 1);
    for (int lambda = 0; lambda <= rad_.maxlambda(); lambda++)
    {
        Rdia_[lambda].reset(rad_.R_tr_dia_diag(lambda).size(), rad_.R_tr_dia_diag(lambda).data());
        Rdia_[lambda].connect(context_, largeDataFlags_);
    }
}

void GPUCGPreconditioner::multiply (BlockArray<Complex> const & p, BlockArray<Complex> & q) const
{
    if (not cmd_.gpu_multiply)
    {
        // user parent's routine
        KPACGPreconditioner::multiply(p,q);
    }
    else
    {
        // shorthands
        std::size_t Nsegsiz = bspline_atom_.Nspline() * bspline_proj_.Nspline();
        
        // device data handles
        int location = (cmd_.gpu_host_multiply ? CL_MEM_ALLOC_HOST_PTR : 0);
        cl_mem pgpu = clCreateBuffer(context_, location | CL_MEM_READ_ONLY,  nsrcseg_ * Nsegsiz * sizeof(Complex), nullptr, nullptr);
        cl_mem qgpu = clCreateBuffer(context_, location | CL_MEM_READ_WRITE, ndstseg_ * Nsegsiz * sizeof(Complex), nullptr, nullptr);
        
        // copy angular integrals
        clArrayView<double> fgpu (ang_.f().size(), ang_.f().data());
        fgpu.connect(context_, smallDataFlags_);
        
        // one-electron contribution
        for (unsigned ill = 0; ill < ang_.states().size(); ill++)
        {
            // decode angular momenta
            int l1 = ang_.states()[ill].first;
            int l2 = ang_.states()[ill].second;
            
            // copy source vector to the device memory
            clEnqueueWriteBuffer(queue_, pgpu, CL_TRUE, 0, Nsegsiz * sizeof(Complex), p[ill].data(), 0, nullptr, nullptr);
            clFinish(queue_);
            
            // multiply by diagonal block (one-electron contribution)
            clSetKernelArg(mml1_, 0, sizeof(double), &E_);
            clSetKernelArg(mml1_, 1, sizeof(cl_mem), &S_atom_p_.handle());
            clSetKernelArg(mml1_, 2, sizeof(cl_mem), &D_atom_p_.handle());
            clSetKernelArg(mml1_, 3, sizeof(cl_mem), &Mm1_tr_atom_p_.handle());
            clSetKernelArg(mml1_, 4, sizeof(cl_mem), &Mm2_atom_p_.handle());
            clSetKernelArg(mml1_, 5, sizeof(cl_mem), &S_proj_p_.handle());
            clSetKernelArg(mml1_, 6, sizeof(cl_mem), &D_proj_p_.handle());
            clSetKernelArg(mml1_, 7, sizeof(cl_mem), &Mm1_tr_proj_p_.handle());
            clSetKernelArg(mml1_, 8, sizeof(cl_mem), &Mm2_proj_p_.handle());
            clSetKernelArg(mml1_, 9, sizeof(int),    &l1);
            clSetKernelArg(mml1_,10, sizeof(int),    &l2);
            clSetKernelArg(mml1_,11, sizeof(cl_mem), &pgpu);
            clSetKernelArg(mml1_,12, sizeof(cl_mem), &qgpu);
            clEnqueueNDRangeKernel(queue_, mml1_, 1, nullptr, &Nsegsiz, nullptr, 0, nullptr, nullptr);
            clFinish(queue_);
            
            // read back the product
            clEnqueueReadBuffer(queue_, qgpu, CL_TRUE, 0, Nsegsiz * sizeof(Complex), q[ill].data(), 0, nullptr, nullptr);
            clFinish(queue_);
        }
        
        // two-electron contribution
        for (int lambda = 0; lambda <= rad_.maxlambda(); lambda++)
        {
            // memory offset
            cl_int foffset = lambda * ang_.states().size() * ang_.states().size();
            
            // set kernel arguments
            clSetKernelArg(mml2_dcpl_offset_, 0, sizeof(cl_mem), &t_atom_.handle());
            clSetKernelArg(mml2_dcpl_offset_, 1, sizeof(cl_mem), &t_proj_.handle());
            clSetKernelArg(mml2_dcpl_offset_, 2, sizeof(int),    &(lambda));
            clSetKernelArg(mml2_dcpl_offset_, 3, sizeof(cl_mem), &(fgpu.handle()));
            clSetKernelArg(mml2_dcpl_offset_, 4, sizeof(cl_int), &foffset);
            clSetKernelArg(mml2_dcpl_offset_, 5, sizeof(cl_mem), &(M_L_atom_[lambda].handle()));
            clSetKernelArg(mml2_dcpl_offset_, 6, sizeof(cl_mem), &(M_mLm1_atom_[lambda].handle()));
            clSetKernelArg(mml2_dcpl_offset_, 7, sizeof(cl_mem), &(M_L_proj_[lambda].handle()));
            clSetKernelArg(mml2_dcpl_offset_, 8, sizeof(cl_mem), &(M_mLm1_proj_[lambda].handle()));
            clSetKernelArg(mml2_dcpl_offset_, 9, sizeof(cl_mem), &pgpu);
            clSetKernelArg(mml2_dcpl_offset_,10, sizeof(cl_mem), &qgpu);
            clSetKernelArg(mml2_cpld_offset_, 0, sizeof(cl_mem), &t_atom_.handle());
            clSetKernelArg(mml2_cpld_offset_, 1, sizeof(cl_mem), &t_proj_.handle());
            clSetKernelArg(mml2_cpld_offset_, 2, sizeof(int),    &(lambda));
            clSetKernelArg(mml2_cpld_offset_, 3, sizeof(cl_mem), &(fgpu.handle()));
            clSetKernelArg(mml2_cpld_offset_, 4, sizeof(cl_int), &foffset);
            clSetKernelArg(mml2_cpld_offset_, 5, sizeof(cl_mem), &(Mi_L_atom_[lambda].handle()));
            clSetKernelArg(mml2_cpld_offset_, 6, sizeof(cl_mem), &(Mi_mLm1_atom_[lambda].handle()));
            clSetKernelArg(mml2_cpld_offset_, 7, sizeof(cl_mem), &(Mi_L_proj_[lambda].handle()));
            clSetKernelArg(mml2_cpld_offset_, 8, sizeof(cl_mem), &(Mi_mLm1_proj_[lambda].handle()));
            clSetKernelArg(mml2_cpld_offset_, 9, sizeof(cl_mem), &(Rdia_[lambda].handle()));
            clSetKernelArg(mml2_cpld_offset_,10, sizeof(cl_mem), &pgpu);
            clSetKernelArg(mml2_cpld_offset_,11, sizeof(cl_mem), &qgpu);
            
            // for all destination vector segments
            for (cl_short first_srcseg = 0; first_srcseg < (cl_short)ang_.states().size(); first_srcseg += nsrcseg_)
            {
                // copy source vector segment to the device memory
                for (cl_short illp = first_srcseg; illp < std::min<cl_short>(first_srcseg + nsrcseg_, ang_.states().size()); illp++)
                    clEnqueueWriteBuffer(queue_, pgpu, CL_TRUE, (illp - first_srcseg) * Nsegsiz * sizeof(Complex), Nsegsiz * sizeof(Complex), p[illp].data(), 0, nullptr, nullptr);
                clFinish(queue_);
                
                // for all source vector segments
                for (cl_short first_dstseg = 0; first_dstseg < (cl_short)ang_.states().size(); first_dstseg += ndstseg_)
                {
                    // copy destination vector segments to the device memory
                    for (cl_short ill = first_dstseg; ill < std::min<cl_short>(first_dstseg + ndstseg_, ang_.states().size()); ill++)
                        clEnqueueWriteBuffer(queue_, qgpu, CL_TRUE, (ill - first_dstseg) * Nsegsiz * sizeof(Complex), Nsegsiz * sizeof(Complex), q[ill].data(), 0, nullptr, nullptr);
                    clFinish(queue_);
                    
                    // execute the kernel
                    clSetKernelArg(mml2_dcpl_offset_, 11, sizeof(cl_short), &first_srcseg);
                    clSetKernelArg(mml2_dcpl_offset_, 12, sizeof(cl_short), &first_dstseg);
                    clEnqueueNDRangeKernel(queue_, mml2_dcpl_offset_, 1, nullptr, &Nsegsiz, nullptr, 0, nullptr, nullptr);
                    clFinish(queue_);
                    
                    std::size_t Nband = bspline_atom_.Nspline() * (2 * bspline_atom_.order() + 1);
                    
                    clSetKernelArg(mml2_cpld_offset_, 12, sizeof(cl_short), &first_srcseg);
                    clSetKernelArg(mml2_cpld_offset_, 13, sizeof(cl_short), &first_dstseg);
                    clEnqueueNDRangeKernel(queue_, mml2_cpld_offset_, 1, nullptr, &Nband, nullptr, 0, nullptr, nullptr);
                    clFinish(queue_);
                    
                    // read back the product
                    for (cl_short ill = first_dstseg; ill < std::min<cl_short>(first_dstseg + ndstseg_, ang_.states().size()); ill++)
                        clEnqueueReadBuffer(queue_, qgpu, CL_TRUE, (ill - first_dstseg) * Nsegsiz * sizeof(Complex), Nsegsiz * sizeof(Complex), q[ill].data(), 0, nullptr, nullptr);
                    clFinish(queue_);
                }
            }
        }
        clFinish(queue_);
        
        // release device memory
        clReleaseMemObject(pgpu);
        clReleaseMemObject(qgpu);
        fgpu.disconnect();
    }
}

void GPUCGPreconditioner::precondition (BlockArray<Complex> const & r, BlockArray<Complex> & z) const
{
    // shorthands
    std::size_t Nspline_atom = bspline_atom_.Nspline();
    std::size_t Nspline_proj = bspline_proj_.Nspline();
    std::size_t Nsegsiz = Nspline_atom * Nspline_proj;
    
    // performance timers
    std::size_t us_prec = 0, us_mmul = 0, us_spro = 0, us_axby = 0, us_norm = 0;
    std::size_t us_mmul_1 = 0;
    
    // round 'Nsegsiz' to nearest larger multiple of Nlocal_
    std::size_t Nglobal = Nlocal_ * ((Nsegsiz + Nlocal_ - 1) / Nlocal_);
    
    // iterations
    iArray n (ang_.states().size());
    
    // for all diagonal blocks
    for (int ill = 0; ill < (int)ang_.states().size(); ill++) if (par_.isMyWork(ill))
    {
        // get angular momenta
        int l1 = ang_.states()[ill].first;
        int l2 = ang_.states()[ill].second;
        
        // load blocks
        if (cmd_.outofcore)
        {
            const_cast<BlockArray<Complex>&>(r).hdfload(ill);
            z.hdfload(ill);
        }
        
        // create segment views
        clArrayView<Complex> rview (r[ill], 0, Nsegsiz);  rview.connect(context_, largeDataFlags_);
        clArrayView<Complex> zview (z[ill], 0, Nsegsiz);  zview.connect(context_, largeDataFlags_);
        
        // initialize block preconditioner
        this->CG_init(ill);
        
        // preconditioner matrices
        clArrayView<Complex> prec1a (Nspline_atom * Nspline_atom, prec_atom_[l1].invCl_invsqrtS.data().data());  prec1a.connect(context_, largeDataFlags_);
        clArrayView<Complex> prec2a (Nspline_proj * Nspline_proj, prec_proj_[l2].invCl_invsqrtS.data().data());  prec2a.connect(context_, largeDataFlags_);
        clArrayView<Complex> Dl1 (Nspline_atom, prec_atom_[l1].Dl.data());                                       Dl1.connect(context_, smallDataFlags_);
        clArrayView<Complex> Dl2 (Nspline_proj, prec_proj_[l2].Dl.data());                                       Dl2.connect(context_, smallDataFlags_);
        clArrayView<Complex> prec1b (Nspline_atom * Nspline_atom, prec_atom_[l1].invsqrtS_Cl.data().data());     prec1b.connect(context_, largeDataFlags_);
        clArrayView<Complex> prec2b (Nspline_proj * Nspline_proj, prec_proj_[l2].invsqrtS_Cl.data().data());     prec2b.connect(context_, largeDataFlags_);
        
        // allocation (and upload) of an OpenCL array
        auto new_opencl_array = [&](std::size_t n, std::string name) -> clArray<Complex>
        {
            // create array
            clArray<Complex> a(n);
            
            // connect the array to GPU
            a.connect(context_, largeDataFlags_);
            
            // use this array
            return a;
        };
        
        // multiplies vector by the ill-th diagonal block
        auto inner_mmul = [&](const clArrayView<Complex> a, clArrayView<Complex> b) -> void
        {
            // multiply
            //      b = A · a
            
            Timer timer;
            
            // one-electron contribution
            clSetKernelArg(mml1_, 0, sizeof(double), &E_);
            clSetKernelArg(mml1_, 1, sizeof(cl_mem), &S_atom_p_.handle());
            clSetKernelArg(mml1_, 2, sizeof(cl_mem), &D_atom_p_.handle());
            clSetKernelArg(mml1_, 3, sizeof(cl_mem), &Mm1_tr_atom_p_.handle());
            clSetKernelArg(mml1_, 4, sizeof(cl_mem), &Mm2_atom_p_.handle());
            clSetKernelArg(mml1_, 5, sizeof(cl_mem), &S_proj_p_.handle());
            clSetKernelArg(mml1_, 6, sizeof(cl_mem), &D_proj_p_.handle());
            clSetKernelArg(mml1_, 7, sizeof(cl_mem), &Mm1_tr_proj_p_.handle());
            clSetKernelArg(mml1_, 8, sizeof(cl_mem), &Mm2_proj_p_.handle());
            clSetKernelArg(mml1_, 9, sizeof(int),    &l1);
            clSetKernelArg(mml1_,10, sizeof(int),    &l2);
            clSetKernelArg(mml1_,11, sizeof(cl_mem), &a.handle());
            clSetKernelArg(mml1_,12, sizeof(cl_mem), &b.handle());
            clEnqueueNDRangeKernel(queue_, mml1_, 1, nullptr, &Nsegsiz, nullptr, 0, nullptr, nullptr);
            clFinish(queue_);
            
            us_mmul_1 += timer.microseconds();
            
            // two-electron contribution
            for (int lambda = 0; lambda <= ang_.maxlambda(); lambda++) if (ang_.f(ill,ill,lambda) != 0)
            {
                double f = ang_.f(ill,ill,lambda);
                
                clSetKernelArg(mml2_dcpl_, 0, sizeof(cl_mem), &t_atom_.handle());
                clSetKernelArg(mml2_dcpl_, 1, sizeof(cl_mem), &t_proj_.handle());
                clSetKernelArg(mml2_dcpl_, 2, sizeof(int),    &lambda);
                clSetKernelArg(mml2_dcpl_, 3, sizeof(double), &f);
                clSetKernelArg(mml2_dcpl_, 4, sizeof(cl_mem), &M_L_atom_[lambda].handle());
                clSetKernelArg(mml2_dcpl_, 5, sizeof(cl_mem), &M_mLm1_atom_[lambda].handle());
                clSetKernelArg(mml2_dcpl_, 6, sizeof(cl_mem), &M_L_proj_[lambda].handle());
                clSetKernelArg(mml2_dcpl_, 7, sizeof(cl_mem), &M_mLm1_proj_[lambda].handle());
                clSetKernelArg(mml2_dcpl_, 8, sizeof(cl_mem), &a.handle());
                clSetKernelArg(mml2_dcpl_, 9, sizeof(cl_mem), &b.handle());
                clEnqueueNDRangeKernel(queue_, mml2_dcpl_, 1, nullptr, &Nsegsiz, nullptr, 0, nullptr, nullptr);
                clFinish(queue_);
                
                std::size_t Nband = bspline_atom_.Nspline() * (2 * bspline_atom_.order() + 1);
                
                clSetKernelArg(mml2_cpld_, 0, sizeof(cl_mem), &t_atom_.handle());
                clSetKernelArg(mml2_cpld_, 1, sizeof(cl_mem), &t_proj_.handle());
                clSetKernelArg(mml2_cpld_, 2, sizeof(int),    &lambda);
                clSetKernelArg(mml2_cpld_, 3, sizeof(double), &f);
                clSetKernelArg(mml2_cpld_, 4, sizeof(cl_mem), &Mi_L_atom_[lambda].handle());
                clSetKernelArg(mml2_cpld_, 5, sizeof(cl_mem), &Mi_mLm1_atom_[lambda].handle());
                clSetKernelArg(mml2_cpld_, 6, sizeof(cl_mem), &Mi_L_proj_[lambda].handle());
                clSetKernelArg(mml2_cpld_, 7, sizeof(cl_mem), &Mi_mLm1_proj_[lambda].handle());
                clSetKernelArg(mml2_cpld_, 8, sizeof(cl_mem), &Rdia_[lambda].handle());
                clSetKernelArg(mml2_cpld_, 9, sizeof(cl_mem), &a.handle());
                clSetKernelArg(mml2_cpld_,10, sizeof(cl_mem), &b.handle());
                clEnqueueNDRangeKernel(queue_, mml2_cpld_, 1, nullptr, &Nband, nullptr, 0, nullptr, nullptr);
                clFinish(queue_);
            }
            
            us_mmul += timer.microseconds();
        };
        
        // applies KPA preconditioner (two "kron-dots")
        auto inner_prec = [&](const clArrayView<Complex> x, clArrayView<Complex> y) -> void
        {
            // multiply by approximate inverse block
            Timer timer;
            
            // "gsize" is Nspline rounded to nearest greater multiple of "blocksize_"
            std::size_t gsize_atom = blocksize_ * ((Nspline_atom + blocksize_ - 1) / blocksize_);
            std::size_t gsize_proj = blocksize_ * ((Nspline_proj + blocksize_ - 1) / blocksize_);
            std::size_t gsize[2], lsize[2] = { blocksize_, blocksize_ };
            
            // matrix dimensions
            int m, n, k;
            
            m = Nspline_proj; n = Nspline_atom; k = Nspline_proj;
            gsize[0] = gsize_proj; gsize[1] = gsize_atom;
            clSetKernelArg(mabt_, 0, sizeof(int), &m);
            clSetKernelArg(mabt_, 1, sizeof(int), &n);
            clSetKernelArg(mabt_, 2, sizeof(int), &k);
            clSetKernelArg(mabt_, 3, sizeof(cl_mem), &prec2a.handle());
            clSetKernelArg(mabt_, 4, sizeof(cl_mem), &x.handle());
            clSetKernelArg(mabt_, 5, sizeof(cl_mem), &tmA_.handle());
            clEnqueueNDRangeKernel(queue_, mabt_, 2, nullptr, gsize, lsize, 0, nullptr, nullptr);
            clFinish(queue_);
            
            m = Nspline_atom; n = Nspline_proj; k = Nspline_atom;
            gsize[0] = gsize_atom; gsize[1] = gsize_proj;
            clSetKernelArg(mabt_, 0, sizeof(int), &m);
            clSetKernelArg(mabt_, 1, sizeof(int), &n);
            clSetKernelArg(mabt_, 2, sizeof(int), &k);
            clSetKernelArg(mabt_, 3, sizeof(cl_mem), &prec1a.handle());
            clSetKernelArg(mabt_, 4, sizeof(cl_mem), &tmA_.handle());
            clSetKernelArg(mabt_, 5, sizeof(cl_mem), &y.handle());
            clEnqueueNDRangeKernel(queue_, mabt_, 2, nullptr, gsize, lsize, 0, nullptr, nullptr);
            clFinish(queue_);
            
            clSetKernelArg(krdv_, 0, sizeof(Complex), &E_);
            clSetKernelArg(krdv_, 1, sizeof(cl_mem),  &Dl1.handle());
            clSetKernelArg(krdv_, 2, sizeof(cl_mem),  &Dl2.handle());
            clSetKernelArg(krdv_, 3, sizeof(cl_mem),  &y.handle());
            clEnqueueNDRangeKernel(queue_, krdv_, 1, nullptr, &Nspline_proj, nullptr, 0, nullptr, nullptr);
            clFinish(queue_);
            
            m = Nspline_proj; n = Nspline_atom; k = Nspline_proj;
            gsize[0] = gsize_proj; gsize[1] = gsize_atom;
            clSetKernelArg(mabt_, 0, sizeof(int), &m);
            clSetKernelArg(mabt_, 1, sizeof(int), &n);
            clSetKernelArg(mabt_, 2, sizeof(int), &k);
            clSetKernelArg(mabt_, 3, sizeof(cl_mem), &prec2b.handle());
            clSetKernelArg(mabt_, 4, sizeof(cl_mem), &y.handle());
            clSetKernelArg(mabt_, 5, sizeof(cl_mem), &tmA_.handle());
            clEnqueueNDRangeKernel(queue_, mabt_, 2, nullptr, gsize, lsize, 0, nullptr, nullptr);
            clFinish(queue_);
            
            m = Nspline_atom; n = Nspline_proj; k = Nspline_atom;
            gsize[0] = gsize_atom; gsize[1] = gsize_proj;
            clSetKernelArg(mabt_, 0, sizeof(int), &m);
            clSetKernelArg(mabt_, 1, sizeof(int), &n);
            clSetKernelArg(mabt_, 2, sizeof(int), &k);
            clSetKernelArg(mabt_, 3, sizeof(cl_mem), &prec1b.handle());
            clSetKernelArg(mabt_, 4, sizeof(cl_mem), &tmA_.handle());
            clSetKernelArg(mabt_, 5, sizeof(cl_mem), &y.handle());
            clEnqueueNDRangeKernel(queue_, mabt_, 2, nullptr, gsize, lsize, 0, nullptr, nullptr);
            clFinish(queue_);
            
            us_prec += timer.microseconds();
        };
        
        // computes norm of the vector
        auto compute_norm = [&](const clArrayView<Complex> x) -> double
        {
            // multiply
            //     |x|² -> nrm
            
            Timer timer;
            
            clSetKernelArg(norm_, 0, sizeof(cl_mem), &x.handle());
            clSetKernelArg(norm_, 1, sizeof(cl_mem), &nrm_.handle());
            clEnqueueNDRangeKernel(queue_, norm_, 1, nullptr, &Nglobal, &Nlocal_, 0, nullptr, nullptr);
            nrm_.EnqueueDownload(queue_);
            clFinish(queue_);
            
            us_norm += timer.microseconds();
            
            // return square root of the sum
            return std::sqrt(sum(nrm_));
        };
        
        // computes scalar product of two arrays
        auto scalar_product = [&](const clArrayView<Complex> x, /* const */ clArrayView<Complex> y) -> Complex
        {
            // multiply
            //     x * y -> tmp
            
            Timer timer;
            
            clSetKernelArg(spro_, 0, sizeof(cl_mem), &x.handle());
            clSetKernelArg(spro_, 1, sizeof(cl_mem), &y.handle());
            clSetKernelArg(spro_, 2, sizeof(cl_mem), &tmp_.handle());
            clEnqueueNDRangeKernel(queue_, spro_, 1, nullptr, &Nglobal, &Nlocal_, 0, nullptr, nullptr);
            tmp_.EnqueueDownload(queue_);
            clFinish(queue_);
            
            us_spro += timer.microseconds();
            
            // sum the product of the arrays
            return sum(tmp_);
        };
        
        // weighted sum of two arrays
        auto axby = [&](Complex a, clArrayView<Complex> x, Complex b, const clArrayView<Complex> y) -> void
        {
            // multiply
            //     a * x + b * y -> z
            
            Timer timer;
            
            clSetKernelArg(axby_, 0, sizeof(Complex), &a);
            clSetKernelArg(axby_, 1, sizeof(cl_mem),  &x.handle());
            clSetKernelArg(axby_, 2, sizeof(Complex), &b);
            clSetKernelArg(axby_, 3, sizeof(cl_mem),  &y.handle());
            clEnqueueNDRangeKernel(queue_, axby_, 1, nullptr, &Nglobal, nullptr, 0, nullptr, nullptr);
            clFinish(queue_);
            
            us_axby += timer.microseconds();
        };
        
        // solve using the CG solver
        ConjugateGradients < Complex, clArray<Complex>, clArrayView<Complex> > CG;
        n[ill] = CG.solve
        (
            rview,                  // rhs
            zview,                  // solution
            cmd_.prec_itertol,      // preconditioner tolerance
            0,                      // min. iterations
            Nsegsiz,                // max. iteration
            inner_prec,             // preconditioner
            inner_mmul,             // matrix multiplication
            false,                  // verbose output
            compute_norm,           // norm of an array
            scalar_product,         // scalar product of two arrays
            axby,                   // weighted sum of two arrays
            new_opencl_array        // allocate and connect a new array
        );
        
        // download data arrays from the GPU
        zview.EnqueueDownload(queue_);
        clFinish(queue_);
        
        // free GPU memory
        rview.disconnect();
        zview.disconnect();
        prec1a.disconnect();
        prec2a.disconnect();
        prec1b.disconnect();
        prec2b.disconnect();
        Dl1.disconnect();
        Dl2.disconnect();
        
        // unload blocks
        if (cmd_.outofcore)
        {
            const_cast<BlockArray<Complex>&>(r)[ill].drop();
            z.hdfsave(ill);
            z[ill].drop();
        }
        
        // release block preconditioner
        this->CG_exit(ill);
    }
    
    // broadcast inner preconditioner iterations
    par_.sync(n.data(), 1, ang_.states().size());
    
    // inner preconditioner info (max and avg number of iterations)
    std::cout << " | ";
    std::cout << std::setw(5) << (*std::min_element(n.begin(), n.end()));
    std::cout << std::setw(5) << (*std::max_element(n.begin(), n.end()));
    std::cout << std::setw(5) << format("%g", std::accumulate(n.begin(), n.end(), 0) / float(n.size()));
    
    // GPU kernel timing
    std::size_t us_total = us_axby + us_mmul + us_norm + us_prec + us_spro;
    std::cout << " [prec: " << format("%2d", int(us_prec * 100. / us_total)) << "%"
              << ", mul1: " << format("%2d", int(us_mmul_1 * 100. / us_total)) << "%"
              << ", mul2: " << format("%2d", int((us_mmul-us_mmul_1) * 100. / us_total)) << "%"
              << ", axby: " << format("%2d", int(us_axby * 100. / us_total)) << "%"
              << ", norm: " << format("%2d", int(us_norm * 100. / us_total)) << "%"
              << ", spro: " << format("%2d", int(us_spro * 100. / us_total)) << "%"
              << "]";
}

void GPUCGPreconditioner::finish ()
{
    tmp_.disconnect();
    nrm_.disconnect();
    tmA_.disconnect();
    D_atom_p_.disconnect();        D_proj_p_.disconnect();
    S_atom_p_.disconnect();        S_proj_p_.disconnect();
    Mm1_tr_atom_p_.disconnect();   Mm1_tr_proj_p_.disconnect();
    Mm2_atom_p_.disconnect();      Mm2_proj_p_.disconnect();
    for (int lambda = 0; lambda <= rad_.maxlambda(); lambda++)
    {
        Mi_L_atom_[lambda].disconnect();
        Mi_mLm1_atom_[lambda].disconnect();
        Mi_L_proj_[lambda].disconnect();
        Mi_mLm1_proj_[lambda].disconnect();
        Rdia_[lambda].disconnect();
    }
    KPACGPreconditioner::finish();
}

#endif
